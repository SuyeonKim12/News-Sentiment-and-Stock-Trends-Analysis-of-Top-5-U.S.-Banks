{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank of America"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/suyeonkim/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/suyeonkim/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/suyeonkim/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Bank                                              Title  \\\n",
      "0  Bank of America  BofA Launches CashPro® Insights – Latest Digit...   \n",
      "1  Bank of America  Bank of America profit falls on one-off charge...   \n",
      "2  Bank of America  Bank of America Reports Fourth-Quarter 2023 Fi...   \n",
      "3  Bank of America  Bank of America’s latest office attendance too...   \n",
      "4  Bank of America  Bank of America invests in blockchain, AI in d...   \n",
      "\n",
      "           Date  \n",
      "0   Jan 9, 2024  \n",
      "1  Jan 12, 2024  \n",
      "2  Jan 12, 2024  \n",
      "3  Jan 24, 2024  \n",
      "4  Jan 29, 2024  \n"
     ]
    }
   ],
   "source": [
    "# Import all the libraries and packages\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import yfinance as yf\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define sentiment analysis thresholds\n",
    "strong_pos = 0.6\n",
    "weak_pos = 0.2\n",
    "neutral_lower, neutral_upper = -0.2, 0.2\n",
    "weak_neg = -0.6\n",
    "\n",
    "# Web-scape Google News articles for the given bank within the specified date range.\n",
    "def scrape_news(bank_name, start_date, end_date):\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36\")\n",
    "    chrome_options.add_argument(\"--start-maximized\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    \n",
    "    service = Service('/usr/local/bin/chromedriver')\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    base_url = \"https://www.google.com/search?q={query}&tbm=nws&tbs=cdr:1,cd_min:{start_date},cd_max:{end_date}\"\n",
    "    current_date = datetime.strptime(start_date, \"%m-%d-%Y\")\n",
    "    end_date = datetime.strptime(end_date, \"%m-%d-%Y\")\n",
    "    \n",
    "    titles, dates = [], []\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        next_date = current_date + timedelta(days=30)\n",
    "        if next_date > end_date:\n",
    "            next_date = end_date\n",
    "\n",
    "        formatted_start = current_date.strftime('%m/%d/%Y')\n",
    "        formatted_end = next_date.strftime('%m/%d/%Y')\n",
    "        url = base_url.format(query=bank_name, start_date=formatted_start, end_date=formatted_end)\n",
    "\n",
    "        for page in range(0, 100, 10):\n",
    "            paginated_url = f\"{url}&start={page}\"\n",
    "            driver.get(paginated_url)\n",
    "            time.sleep(random.uniform(3, 7))  # Randomized sleep to avoid bot detection\n",
    "            \n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            page_titles = [title.text for title in soup.select('div.n0jPhd.ynAwRc.MBeuO.nDgy9d')]\n",
    "            page_dates = [date.text for date in soup.select('div.OSrXXb.rbYSKb.LfVVr span')]\n",
    "            \n",
    "            titles.extend(page_titles)\n",
    "            dates.extend(page_dates)\n",
    "            \n",
    "            if not page_titles:\n",
    "                break\n",
    "        \n",
    "        current_date = next_date + timedelta(days=1)\n",
    "\n",
    "    driver.quit()\n",
    "    news_df = pd.DataFrame({'Bank': bank_name, 'Title': titles, 'Date': dates})\n",
    "    news_df.to_csv(f\"{bank_name}_news.csv\", index=False)\n",
    "    return news_df\n",
    "\n",
    "# Example usage\n",
    "news_df = scrape_news(\"Bank of America\", \"01-01-2024\", \"12-30-2024\")\n",
    "print(news_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Bank                                              Title  \\\n",
      "0  Bank of America  BofA Launches CashPro® Insights – Latest Digit...   \n",
      "1  Bank of America  Bank of America profit falls on one-off charge...   \n",
      "2  Bank of America  Bank of America Reports Fourth-Quarter 2023 Fi...   \n",
      "3  Bank of America  Bank of America’s latest office attendance too...   \n",
      "4  Bank of America  Bank of America invests in blockchain, AI in d...   \n",
      "\n",
      "           Date                                       Cleaned Text  \n",
      "0   Jan 9, 2024  bofa launches cashpro® insights – latest digit...  \n",
      "1  Jan 12, 2024  bank america profit falls oneoff charges share...  \n",
      "2  Jan 12, 2024  bank america reports fourthquarter 2023 financ...  \n",
      "3  Jan 24, 2024  bank america ’ latest office attendance tool ‘...  \n",
      "4  Jan 29, 2024    bank america invests blockchain ai digital push  \n",
      "              Bank                                              Title  \\\n",
      "0  Bank of America  BofA Launches CashPro® Insights – Latest Digit...   \n",
      "1  Bank of America  Bank of America profit falls on one-off charge...   \n",
      "2  Bank of America  Bank of America Reports Fourth-Quarter 2023 Fi...   \n",
      "3  Bank of America  Bank of America Reports Fourth-Quarter 2023 Fi...   \n",
      "4  Bank of America  Bank of America’s latest office attendance too...   \n",
      "\n",
      "           Date                                       Cleaned Text  \\\n",
      "0   Jan 9, 2024  bofa launches cashpro® insights – latest digit...   \n",
      "1  Jan 12, 2024  bank america profit falls oneoff charges share...   \n",
      "2  Jan 12, 2024  bank america reports fourthquarter 2023 financ...   \n",
      "3  Jan 12, 2024  bank america reports fourthquarter 2023 financ...   \n",
      "4  Jan 24, 2024  bank america ’ latest office attendance tool ‘...   \n",
      "\n",
      "       Sentiment  Average Compound Score  \n",
      "0  Weak Positive                  0.5267  \n",
      "1  Weak Positive                  0.4588  \n",
      "2        Neutral                  0.0000  \n",
      "3        Neutral                  0.0000  \n",
      "4        Neutral                  0.0000  \n",
      "         Date             bank  avg_sentiment  strong_positive  weak_positive  \\\n",
      "0  2024-01-01  Bank of America         0.0000                0              0   \n",
      "1  2024-01-02  Bank of America         0.0000                0              0   \n",
      "2  2024-01-03  Bank of America         0.7964                1              0   \n",
      "3  2024-01-04  Bank of America         0.0000                0              0   \n",
      "4  2024-01-05  Bank of America         0.2312                1              1   \n",
      "\n",
      "   neutral  weak_negative  strong_negative  \n",
      "0        2              0                0  \n",
      "1        1              0                0  \n",
      "2        0              0                0  \n",
      "3        1              0                0  \n",
      "4        2              0                0  \n",
      "         Date  Stock Price\n",
      "0  2024-01-02    33.058743\n",
      "1  2024-01-03    32.697918\n",
      "2  2024-01-04    32.961224\n",
      "3  2024-01-05    33.575588\n",
      "4  2024-01-08    33.312290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Clean the text by lowercasing, removing punctuation, and stop words.\n",
    "\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        words = word_tokenize(text)\n",
    "        filtered_words = [word for word in words if word not in stop_words]\n",
    "        return ' '.join(filtered_words)\n",
    "    return text\n",
    "\n",
    "# Apply cleaning function\n",
    "news_df['Cleaned Text'] = news_df['Title'].apply(clean_text)\n",
    "print(news_df.head())\n",
    "\n",
    "# Perform sentiment analysis on the cleaned news article titles.\n",
    "\n",
    "def analyze_sentiment(news_df):\n",
    "    sentiment = SentimentIntensityAnalyzer()\n",
    "    sentiment_data = []\n",
    "\n",
    "    for _, row in news_df.iterrows():\n",
    "        cleaned_text = row['Cleaned Text']\n",
    "        sentences = nltk.tokenize.sent_tokenize(cleaned_text)\n",
    "        compound_scores = [sentiment.polarity_scores(sentence)['compound'] for sentence in sentences]\n",
    "        average_compound = sum(compound_scores) / len(compound_scores) if compound_scores else 0\n",
    "\n",
    "        if average_compound > strong_pos:\n",
    "            sentiment_category = \"Strong Positive\"\n",
    "        elif average_compound > weak_pos:\n",
    "            sentiment_category = \"Weak Positive\"\n",
    "        elif neutral_lower <= average_compound <= neutral_upper:\n",
    "            sentiment_category = \"Neutral\"\n",
    "        elif average_compound >= weak_neg:\n",
    "            sentiment_category = \"Weak Negative\"\n",
    "        else:\n",
    "            sentiment_category = \"Strong Negative\"\n",
    "\n",
    "        sentiment_data.append([row['Title'], sentiment_category, average_compound])\n",
    "    \n",
    "    sentiment_df = pd.DataFrame(sentiment_data, columns=['Title', 'Sentiment', 'Average Compound Score'])\n",
    "    news_df = news_df.merge(sentiment_df, on='Title', how='left')\n",
    "    return news_df\n",
    "\n",
    "news_df = analyze_sentiment(news_df)\n",
    "print(news_df.head())\n",
    "\n",
    "# Aggregate sentiment scores by date. & Compute the average sentiment score and counts different sentiment categories.\n",
    "def aggregate_sentiment(news_df):\n",
    "    news_df['Date'] = pd.to_datetime(news_df['Date'], errors='coerce').dt.date\n",
    "\n",
    "    aggregated_df = news_df.groupby('Date').agg(\n",
    "        bank = ('Bank', 'first'),\n",
    "        avg_sentiment=('Average Compound Score', 'mean'),\n",
    "        strong_positive=('Sentiment', lambda x: sum(x == 'Strong Positive')),\n",
    "        weak_positive=('Sentiment', lambda x: sum(x == 'Weak Positive')),\n",
    "        neutral=('Sentiment', lambda x: sum(x == 'Neutral')),\n",
    "        weak_negative=('Sentiment', lambda x: sum(x == 'Weak Negative')),\n",
    "        strong_negative=('Sentiment', lambda x: sum(x == 'Strong Negative'))\n",
    "    ).reset_index()\n",
    "\n",
    "    return aggregated_df\n",
    "\n",
    "aggregated_sentiment_df = aggregate_sentiment(news_df)\n",
    "print(aggregated_sentiment_df.head())\n",
    "\n",
    "# Fetch stock closing prices for the given bank within the date range.\n",
    "\n",
    "\n",
    "def fetch_stock_prices(bank_name, start_date, end_date):\n",
    "    ticker_map = {\n",
    "        \"JPMorgan Chase\": \"JPM\",\n",
    "        \"Bank of America\": \"BAC\",\n",
    "        \"Citigroup\": \"C\",\n",
    "        \"Wells Fargo\": \"WFC\",\n",
    "        \"Goldman Sachs\": \"GS\"\n",
    "    }\n",
    "    \n",
    "    ticker = ticker_map.get(bank_name, None)\n",
    "    \n",
    "    if ticker:\n",
    "        stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "        stock_data = stock_data[['Close']].reset_index()\n",
    "        stock_data.rename(columns={'Close': 'Stock Price'}, inplace=True)\n",
    "        stock_data['Date'] = pd.to_datetime(stock_data['Date']).dt.date\n",
    "        return stock_data\n",
    "    else:\n",
    "        print(\"Ticker not found!\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "stock_df = fetch_stock_prices(\"Bank of America\", \"2024-01-01\", \"2024-12-30\")\n",
    "stock_df.columns = ['Date', 'Stock Price']\n",
    "print(stock_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date             bank  avg_sentiment  strong_positive  weak_positive  \\\n",
      "0  2024-01-01  Bank of America         0.0000                0              0   \n",
      "1  2024-01-02  Bank of America         0.0000                0              0   \n",
      "2  2024-01-03  Bank of America         0.7964                1              0   \n",
      "3  2024-01-04  Bank of America         0.0000                0              0   \n",
      "4  2024-01-05  Bank of America         0.2312                1              1   \n",
      "\n",
      "   neutral  weak_negative  strong_negative  Stock Price  \n",
      "0        2              0                0          NaN  \n",
      "1        1              0                0    33.058743  \n",
      "2        0              0                0    32.697918  \n",
      "3        1              0                0    32.961224  \n",
      "4        2              0                0    33.575588  \n"
     ]
    }
   ],
   "source": [
    "# Merge aggregated_sentiment_df and stock_df\n",
    "def merge_data(aggregated_sentiment_df, stock_df):\n",
    "    aggregated_sentiment_df['Date'] = pd.to_datetime(aggregated_sentiment_df['Date'], errors='coerce').dt.date\n",
    "    stock_df['Date'] = pd.to_datetime(stock_df['Date']).dt.date\n",
    "\n",
    "    final_df = aggregated_sentiment_df.merge(stock_df, on='Date', how='left')\n",
    "    final_df.to_csv(\"final_sentiment_stock_data.csv\", index=False)\n",
    "    return final_df\n",
    "\n",
    "final_data = merge_data(aggregated_sentiment_df, stock_df)\n",
    "final_data.to_csv(\"final_data.csv\", index=False)\n",
    "print(final_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JPMorgan Chase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date            bank  avg_sentiment  strong_positive  weak_positive  \\\n",
      "0  2024-01-01  JPMorgan Chase       0.000000                0              0   \n",
      "1  2024-01-02  JPMorgan Chase       0.440400                0              1   \n",
      "2  2024-01-04  JPMorgan Chase      -0.489450                0              0   \n",
      "3  2024-01-05  JPMorgan Chase       0.049150                0              1   \n",
      "4  2024-01-09  JPMorgan Chase       0.307375                0              3   \n",
      "\n",
      "   neutral  weak_negative  strong_negative  Stock Price  \n",
      "0        1              0                0          NaN  \n",
      "1        0              0                0   167.203125  \n",
      "2        0              2                0   167.579132  \n",
      "3        1              0                0   168.419937  \n",
      "4        1              0                0   166.845917  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "news_df = scrape_news(\"JPMorgan Chase\", \"01-01-2024\", \"12-30-2024\")\n",
    "news_df['Cleaned Text'] = news_df['Title'].apply(clean_text)\n",
    "news_df = analyze_sentiment(news_df)\n",
    "aggregated_sentiment_df = aggregate_sentiment(news_df)\n",
    "stock_df = fetch_stock_prices(\"JPMorgan Chase\", \"2024-01-01\", \"2024-12-30\")\n",
    "stock_df.columns = ['Date', 'Stock Price']\n",
    "final_data2 = merge_data(aggregated_sentiment_df, stock_df)\n",
    "final_data2.to_csv(\"final_data2.csv\", index=False)\n",
    "print(final_data2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citigroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date       bank  avg_sentiment  strong_positive  weak_positive  \\\n",
      "0  2024-01-02  Citigroup        0.11324                0              2   \n",
      "1  2024-01-04  Citigroup        0.09966                0              2   \n",
      "2  2024-01-05  Citigroup        0.00000                0              0   \n",
      "3  2024-01-07  Citigroup        0.00000                0              0   \n",
      "4  2024-01-08  Citigroup        0.00000                0              0   \n",
      "\n",
      "   neutral  weak_negative  strong_negative  Stock Price  \n",
      "0        3              0                0    50.784542  \n",
      "1        3              0                0    51.483509  \n",
      "2        2              0                0    52.019695  \n",
      "3        1              0                0          NaN  \n",
      "4        3              0                0    51.713299  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "news_df = scrape_news(\"Citigroup\", \"01-01-2024\", \"12-30-2024\")\n",
    "news_df['Cleaned Text'] = news_df['Title'].apply(clean_text)\n",
    "news_df = analyze_sentiment(news_df)\n",
    "aggregated_sentiment_df = aggregate_sentiment(news_df)\n",
    "stock_df = fetch_stock_prices(\"Citigroup\", \"2024-01-01\", \"2024-12-30\")\n",
    "stock_df.columns = ['Date', 'Stock Price']\n",
    "final_data3 = merge_data(aggregated_sentiment_df, stock_df)\n",
    "final_data3.to_csv(\"final_data3.csv\", index=False)\n",
    "print(final_data3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goldman Sachs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date           bank  avg_sentiment  strong_positive  weak_positive  \\\n",
      "0  2024-01-02  Goldman Sachs       0.000000                0              0   \n",
      "1  2024-01-03  Goldman Sachs       0.090071                1              1   \n",
      "2  2024-01-04  Goldman Sachs       0.000000                0              0   \n",
      "3  2024-01-05  Goldman Sachs       0.000000                0              0   \n",
      "4  2024-01-08  Goldman Sachs       0.163333                0              3   \n",
      "\n",
      "   neutral  weak_negative  strong_negative  Stock Price  \n",
      "0        2              0                0   379.116272  \n",
      "1        4              1                0   372.760284  \n",
      "2        3              0                0   373.892822  \n",
      "3        3              0                0   377.300262  \n",
      "4        2              1                0   379.662994  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "news_df = scrape_news(\"Goldman Sachs\", \"01-01-2024\", \"12-30-2024\")\n",
    "news_df['Cleaned Text'] = news_df['Title'].apply(clean_text)\n",
    "news_df = analyze_sentiment(news_df)\n",
    "aggregated_sentiment_df = aggregate_sentiment(news_df)\n",
    "stock_df = fetch_stock_prices(\"Goldman Sachs\", \"2024-01-01\", \"2024-12-30\")\n",
    "stock_df.columns = ['Date', 'Stock Price']\n",
    "final_data4 = merge_data(aggregated_sentiment_df, stock_df)\n",
    "final_data4.to_csv(\"final_data4.csv\", index=False)\n",
    "print(final_data4.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wells Fargo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date         bank  avg_sentiment  strong_positive  weak_positive  \\\n",
      "0  2024-01-02  Wells Fargo      -0.273200                0              0   \n",
      "1  2024-01-03  Wells Fargo       0.053633                0              2   \n",
      "2  2024-01-04  Wells Fargo       0.062750                0              4   \n",
      "3  2024-01-05  Wells Fargo       0.168200                0              3   \n",
      "4  2024-01-07  Wells Fargo       0.250000                0              2   \n",
      "\n",
      "   neutral  weak_negative  strong_negative  Stock Price  \n",
      "0        0              1                0    47.823631  \n",
      "1        0              1                0    47.193474  \n",
      "2        1              1                0    47.775150  \n",
      "3        1              0                0    48.395607  \n",
      "4        0              0                0          NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "news_df = scrape_news(\"Wells Fargo\", \"01-01-2024\", \"12-30-2024\")\n",
    "news_df['Cleaned Text'] = news_df['Title'].apply(clean_text)\n",
    "news_df = analyze_sentiment(news_df)\n",
    "aggregated_sentiment_df = aggregate_sentiment(news_df)\n",
    "stock_df = fetch_stock_prices(\"Wells Fargo\", \"2024-01-01\", \"2024-12-30\")\n",
    "stock_df.columns = ['Date', 'Stock Price']\n",
    "final_data5 = merge_data(aggregated_sentiment_df, stock_df)\n",
    "final_data5.to_csv(\"final_data5.csv\", index=False)\n",
    "print(final_data5.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine = pd.concat([final_data, final_data2, final_data3, final_data4, final_data5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the change of Stock Price\n",
    "combine['Stock Change'] = combine['Stock Price'] - combine['Stock Price'].shift(1)\n",
    "\n",
    "# If the previous day's value is NaN, use the value from 2 days ago, then 3 days ago\n",
    "combine['Stock Change'].fillna(combine['Stock Price'] - combine['Stock Price'].shift(2), inplace=True)\n",
    "combine['Stock Change'].fillna(combine['Stock Price'] - combine['Stock Price'].shift(3), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values using forward fill (previous day's price)\n",
    "combine['Calculated Stock Price'] = combine['Stock Price']\n",
    "combine['Calculated Stock Price'] = combine['Calculated Stock Price'].ffill()\n",
    "\n",
    "# Calculate daily percentage change\n",
    "combine['Daily Change (%)'] = combine['Calculated Stock Price'].pct_change() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it as a file\n",
    "combine.to_csv(\"combine.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
